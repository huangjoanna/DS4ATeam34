{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sweet-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import yaml\n",
    "from collections import defaultdict\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-sandwich",
   "metadata": {},
   "source": [
    "### Import column dictionary from yaml\n",
    "\n",
    "The yaml file has information regarding the data in the following form:\n",
    "\n",
    "  ```\n",
    "  dictionary:\n",
    "      school.name:\n",
    "        source: INSTNM\n",
    "        type: autocomplete\n",
    "        description: Institution name\n",
    "        index: fulltext \n",
    "  ```\n",
    "The type indicates the data type and should be indicated when reading in the college scorecard csv.  \n",
    "Null values are written as ```NULL``` or ```PrivacySupressed```.   \n",
    "The dictionary is nested. For the example above, the ```school.name``` key returns four more keys ```source, type, description, index```. Each of those keys returns a value. The colum name is under the nested key ```source```. It needs to be flipped so that the value of ```source``` is the main key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "executive-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-4fce6df8588d>:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_content = yaml.load(yaml_file)\n"
     ]
    }
   ],
   "source": [
    "yaml_file = open(\"data.yaml\", 'r')\n",
    "yaml_content = yaml.load(yaml_file)\n",
    "\n",
    "## Need to flip the dictionary so that the the keys match the column names\n",
    "flippeddict = defaultdict(dict)\n",
    "try:\n",
    "    for key, val in yaml_content[\"dictionary\"].items():\n",
    "        newkey = val['source']\n",
    "        for subkey, subval in val.items():\n",
    "            flippeddict[newkey][subkey] = subval\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "# pprint.pprint(dict(flippeddict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-airfare",
   "metadata": {},
   "source": [
    "*Work in progress, defining columns of interest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "musical-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_interest = ['INSTNM',  \n",
    "                    'COSTT4_A', 'COSTT4_P', 'DEBT_MDN','MN_EARN_WNE_P6','MN_EARN_WNE_P8','MN_EARN_WNE_P10','TUITFTE', 'AVGFACSAL', 'ADM_RATE_ALL', 'SATVR25', 'SATVR75', 'SATMT25', 'SATMT75', 'ACTCM25', \n",
    "                    'ACTCM75', 'UGDS', 'UG25ABV', 'PCTFLOAN', 'CDR3' ]\n",
    "cols_numeric = ['COSTT4_A', 'COSTT4_P', 'DEBT_MDN','MN_EARN_WNE_P6','MN_EARN_WNE_P8','MN_EARN_WNE_P10','TUITFTE', 'AVGFACSAL', 'ADM_RATE_ALL', 'SATVR25', 'SATVR75', 'SATMT25', 'SATMT75', 'ACTCM25', \n",
    "                    'ACTCM75', 'UGDS', 'UG25ABV', 'PCTFLOAN', 'CDR3' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-pharmaceutical",
   "metadata": {},
   "source": [
    "# Import data\n",
    "\n",
    "First a function is defined to read and merge csv files. Next the fucntion is run from the year 1996-2020.   \n",
    "<div class=\"alert-danger\">\n",
    "To do: use yaml file to pipe in dtypes for each column\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "commercial-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function read and merge all years\n",
    "def read_cs_data(year,datadir):\n",
    "    \"\"\"read a CollegeScorecard dataframe\"\"\"\n",
    "    nextyr = str(int(year) + 1)[-2:]\n",
    "    filename = datadir + '/MERGED{}_{}_PP.csv'.format(year,nextyr)\n",
    "    \n",
    "    # Specify dtype because guessing dtypes is very memory intensive\n",
    "    # Specify that \"PrivacySuppressed\" are NaN values\n",
    "    # Eventually can use usecols to specify which columns of interest to import\n",
    "    col = pd.read_csv(filename, dtype='unicode',na_values='PrivacySuppressed') \n",
    "    col['Year'] = pd.Period(str(int(year) + 1),freq='Y')\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "official-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/Users/jhuang/DS4A/CollegeScorecard_Raw_Data_08032021\"\n",
    "df = pd.concat((read_cs_data(str(y),datadir) for y in range(1996,2019)))\n",
    "df = df.set_index(['UNITID','Year'])\n",
    "df_subset = df[cols_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "martial-fisher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITID</th>\n",
       "      <th>Year</th>\n",
       "      <th>OPEID</th>\n",
       "      <th>OPEID6</th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>ACCREDAGENCY</th>\n",
       "      <th>INSTURL</th>\n",
       "      <th>...</th>\n",
       "      <th>FEDSCHCD</th>\n",
       "      <th>BOOKSUPPLY</th>\n",
       "      <th>ROOMBOARD_ON</th>\n",
       "      <th>OTHEREXPENSE_ON</th>\n",
       "      <th>ROOMBOARD_OFF</th>\n",
       "      <th>OTHEREXPENSE_OFF</th>\n",
       "      <th>OTHEREXPENSE_FAM</th>\n",
       "      <th>ENDOWBEGIN</th>\n",
       "      <th>ENDOWEND</th>\n",
       "      <th>DOLPROVIDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100636</td>\n",
       "      <td>1997</td>\n",
       "      <td>01230800</td>\n",
       "      <td>012308</td>\n",
       "      <td>Community College of the Air Force</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>36114-3011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100654</td>\n",
       "      <td>1997</td>\n",
       "      <td>00100200</td>\n",
       "      <td>001002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>35762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100663</td>\n",
       "      <td>1997</td>\n",
       "      <td>00105200</td>\n",
       "      <td>001052</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>35294-0110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100672</td>\n",
       "      <td>1997</td>\n",
       "      <td>00574900</td>\n",
       "      <td>005749</td>\n",
       "      <td>ALABAMA AVIATION AND TECHNICAL COLLEGE</td>\n",
       "      <td>OZARK</td>\n",
       "      <td>AL</td>\n",
       "      <td>36360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100690</td>\n",
       "      <td>1997</td>\n",
       "      <td>02503400</td>\n",
       "      <td>025034</td>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>36117-3553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNITID  Year     OPEID  OPEID6                                  INSTNM  \\\n",
       "0  100636  1997  01230800  012308      Community College of the Air Force   \n",
       "1  100654  1997  00100200  001002                Alabama A & M University   \n",
       "2  100663  1997  00105200  001052     University of Alabama at Birmingham   \n",
       "3  100672  1997  00574900  005749  ALABAMA AVIATION AND TECHNICAL COLLEGE   \n",
       "4  100690  1997  02503400  025034                      Amridge University   \n",
       "\n",
       "         CITY STABBR         ZIP ACCREDAGENCY INSTURL  ... FEDSCHCD  \\\n",
       "0  Montgomery     AL  36114-3011          NaN     NaN  ...      NaN   \n",
       "1      Normal     AL       35762          NaN     NaN  ...      NaN   \n",
       "2  Birmingham     AL  35294-0110          NaN     NaN  ...      NaN   \n",
       "3       OZARK     AL       36360          NaN     NaN  ...      NaN   \n",
       "4  Montgomery     AL  36117-3553          NaN     NaN  ...      NaN   \n",
       "\n",
       "  BOOKSUPPLY ROOMBOARD_ON OTHEREXPENSE_ON ROOMBOARD_OFF OTHEREXPENSE_OFF  \\\n",
       "0        NaN          NaN             NaN           NaN              NaN   \n",
       "1        NaN          NaN             NaN           NaN              NaN   \n",
       "2        NaN          NaN             NaN           NaN              NaN   \n",
       "3        NaN          NaN             NaN           NaN              NaN   \n",
       "4        NaN          NaN             NaN           NaN              NaN   \n",
       "\n",
       "  OTHEREXPENSE_FAM ENDOWBEGIN ENDOWEND DOLPROVIDER  \n",
       "0              NaN        NaN      NaN         NaN  \n",
       "1              NaN        NaN      NaN         NaN  \n",
       "2              NaN        NaN      NaN         NaN  \n",
       "3              NaN        NaN      NaN         NaN  \n",
       "4              NaN        NaN      NaN         NaN  \n",
       "\n",
       "[5 rows x 2393 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-reserve",
   "metadata": {},
   "source": [
    "### Save merged csv to disk\n",
    "\n",
    "Next time, this merged csv can be read directly to skip the time-consuming step of reading each year separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "minor-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ALLMERGED.csv') # Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "latest-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this to read in merged csv directly\n",
    "df = pd.read_csv('ALLMERGED.csv', dtype='unicode',na_values='PrivacySuppressed') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-heart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "monetary-jacob",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "To begin, columns with more than 60% ```NaN``` values are omitted. This can percentage can be changed in the code. Three variables related to earnings post-graduation are added back in, ```MN_EARN_WNE_P6,MN_EARN_WNE_P8,MN_EARN_WNE_P10```. There are likely more that can be added back easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-nirvana",
   "metadata": {},
   "source": [
    "### Dropping columns with too many ```NaN```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "legal-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a table of missing values\n",
    "def missing_values_table(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "            \" columns that have missing values.\")\n",
    "    return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "chinese-focus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 2393 columns.\n",
      "There are 2381 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACCREDAGENCY</th>\n",
       "      <td>163332</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTRANS_4_POOLED</th>\n",
       "      <td>163332</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D100_4_POOLED</th>\n",
       "      <td>163332</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100_L4_POOLED</th>\n",
       "      <td>163332</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100_4_POOLED</th>\n",
       "      <td>163332</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Missing Values  % of Total Values\n",
       "ACCREDAGENCY             163332              100.0\n",
       "DTRANS_4_POOLED          163332              100.0\n",
       "D100_4_POOLED            163332              100.0\n",
       "C100_L4_POOLED           163332              100.0\n",
       "C100_4_POOLED            163332              100.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_val = missing_values_table(df)\n",
    "mis_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ordered-rebate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-176-056a24831277>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dropna[col] = df[col]\n"
     ]
    }
   ],
   "source": [
    "# Drop columms with more than 60% NaN\n",
    "df_dropna = df.dropna(thresh=df.shape[0]*0.6,how='all',axis=1)\n",
    "\n",
    "# Add back in certain columns\n",
    "cols_to_add = ['MN_EARN_WNE_P6','MN_EARN_WNE_P8','MN_EARN_WNE_P10']\n",
    "for col in cols_to_add:\n",
    "    df_dropna[col] = df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "brilliant-breakdown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (163332, 2393)  Shape after: (163332, 350)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape before:\", df.shape, \" Shape after:\", df_dropna.shape)\n",
    "\n",
    "myfile = open('dropna_columns.txt', 'w')\n",
    "for col in df_dropna.columns:\n",
    "    try:\n",
    "#         print(col,\":\", flippeddict[col][\"description\"])\n",
    "        var1=col+\":\"+\" \"+flippeddict[col][\"description\"]\n",
    "        myfile.write(\"%s\\n\" % var1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-subscription",
   "metadata": {},
   "source": [
    "### Use dictionary from yaml to change column dtypes\n",
    "\n",
    "Must do this after defining columns of interest. It is too time consuming to do it for the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "banned-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set dtypes on columns of interest in a dataframe using the yaml flipped dictionary from\n",
    "def setdtypes(cols_of_interest, df, flippeddict):\n",
    "    for col in cols_of_interest:\n",
    "        print(\"Doing \",cols_of_interest)\n",
    "        try:\n",
    "            if flippeddict[col][\"type\"] == \"integer\":\n",
    "                df[col] = df[col].astype(\"int\")\n",
    "                print(\"dtype changed to int.\")\n",
    "            elif flippeddict[col][\"type\"] == \"float\":\n",
    "                df[col] = df[col].astype(\"float\")\n",
    "                print(\"dtype changed to float.\")\n",
    "            else:\n",
    "                pass\n",
    "        except KeyError:\n",
    "            print(\"KeyError, skipping\")\n",
    "            pass\n",
    "        except ValueError:\n",
    "            print(\"ValueError, skipping\")\n",
    "            pass\n",
    "        \n",
    "#     print(flippeddict[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"ACTCM25\"] = df['PCTFLOAN'].astype('float')\n",
    "# df[\"ADM_RATE_ALL\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-delaware",
   "metadata": {},
   "source": [
    "# Determining feature importance\n",
    "\n",
    "Going to try to use some models to determine which features are important. Work in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "constant-railway",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '001057A1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-b3fd5ef879f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_dropna\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MN_EARN_WNE_P6'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'feature_importance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLBDenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[1;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLBDenv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLBDenv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLBDenv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLBDenv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLBDenv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLBDenv/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLBDenv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1896\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLBDenv/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '001057A1'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "model=c(random_state=1)\n",
    " \n",
    "features=df\n",
    " \n",
    "model.fit(features,df_dropna['MN_EARN_WNE_P6'])\n",
    " \n",
    "feature_importance=pd.DataFrame({'feature':list(features.columns),'feature_importance':[abs(i) for i in model.coef_[0]]})\n",
    "feature_importance.sort_values('feature_importance',ascending=False)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-capture",
   "metadata": {},
   "source": [
    "### Plotting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[cols_of_interest]\n",
    "for col in cols_numeric:\n",
    "    df_subset[col] = pd.to_numeric(df_subset[col], errors='coerce')\n",
    "df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_subset, y=\"TUITFTE\", x=\"DEBT_MDN\", bins=50, pthresh=.1, cmap=\"mako\")\n",
    "plt.title(\"Cost of tuition vs Median earnings after 6 years\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
